{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337bc602-09b4-4aaf-800b-d7afc4c894f4",
   "metadata": {},
   "source": [
    "# **Machine Learning para Business Intelligence** \n",
    "#### Profesor: Santiago Neira Hernández"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad99c3-c4a5-4805-b964-125b485cd0e5",
   "metadata": {},
   "source": [
    "## Clase 4. Clasificación - KNN SVM y métricas\n",
    "Habiendo visto los algoritmos de regresión, veamos la implementación de algunos algoritmos de clasificación binaria. El propósito del presente notebook es mostrar:\n",
    "1. Implementación del algoritmo de KNN\n",
    "2. Visualización del tuning por híper-parámetro en KNN\n",
    "3. Implementación del algoritmo de SVM\n",
    "4. Algunas métricas para medir la efectividad de los diferentes modelos\n",
    "\n",
    "**Disclaimer: La base que vamos a usar está limpia (caso muy extraño en la vida real). Para que los modelos corran NO PUEDEN haber nulos en ninguna variable** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf246e0e-bdc7-4d67-8aa6-70125a2345ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Paquetes que vamos a usar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919bb1a7-64db-4269-85b0-dd556af4358c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.K-NN \n",
    "Inspeccionemos inicialmente la base con la que vamos a trabajar.Estaremos trabajando con una base de clientes sobre los cuales tenemos información demográfica y si compraron o no el producto que nosotros vendemos. Esta base tiene 5 variables (Identificador, Género, Edad, Salario Estimado, Y una variable categórica de si compró un producto o no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a11811-3344-4787-94bc-66210246a839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Importación de la base\n",
    "datos=pd.read_csv(\"../Datos/Social_Network_Ads.csv\")\n",
    "datos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c80396-92cb-4c02-875d-663bc6dda2a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde1af5-c306-478a-981d-352cb4b6bae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Inspección simple\n",
    "datos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c611b13-a947-470d-91da-05da9e066e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###Separemos la base entre covariables y etiqueta\n",
    "x = datos.iloc[:,2:4]\n",
    "y = datos.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35381d5a-c0b3-4691-ba20-3de057566710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f155f-327b-4c3a-854d-8373de312c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4352568a-f75f-4258-b71e-edb9ef1dbaef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Veamos cómo se separan los datos visualmente, con base en la etiqueta\n",
    "plt.scatter(x['Age'],x['EstimatedSalary'],c=y)\n",
    "plt.xlabel(\"Edad\")\n",
    "plt.ylabel(\"Salario\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8df803-5880-4e5f-b41a-1fa15af8fbad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Es buena práctica (por temas de dimensionalidad) estandarizar las variables\n",
    "scaler= StandardScaler()\n",
    "x=scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b4045-2553-43f6-bc13-68aa7a9b4085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Train-test split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8ce9f-c7c0-4a02-8435-a9eb2f68f0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1781d-d1d3-44a6-9f27-cd18fc330a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Veamos la nueva gráfica en los datos para entrenar\n",
    "plt.scatter(x_train[:,0],x_train[:,1],c=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe50a4e-f5a6-4da5-8b82-4861046a3289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##La misma gráfica en los datos test\n",
    "plt.scatter(x_test[:,0],x_test[:,1],c=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83623e6e-e08c-4f9b-9f3e-3ce5f4ec838d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###Ahora sí, manos a la obra... ¡Encontremos nuestra primera predicción!\n",
    "knn= KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "##Entrenamos nuestro modelo\n",
    "knn.fit(x_train,y_train)\n",
    "\n",
    "##Evaluamos \n",
    "y_pred=knn.predict(x_test)\n",
    "\n",
    "error=(y_pred!=y_test).mean()*100\n",
    "\n",
    "print(f\"Predijimos un {error}% de datos en test incorrectamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959742eb-41da-4698-a090-71d686e694ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "### Visualicemos la frontera de decisión a medida que el número de vecinos aumenta\n",
    "\n",
    "cmap_py = ListedColormap([\"Red\", \"blue\"])\n",
    "modelos={}\n",
    "for k in [3, 5, 10,20,70]:\n",
    "    neigh = KNeighborsClassifier(n_neighbors = k)\n",
    "    neigh.fit(x, y)\n",
    "    modelos[\"neigh\" + str(k)] = neigh\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (5, 5))\n",
    "\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(estimator = modelos[\"neigh\" + str(k)],  X = x, cmap = cmap_py,\n",
    "    ax = ax, response_method = \"predict\", plot_method = \"contourf\",\n",
    "    xlabel = \"Age\", ylabel = \"ExpectedSalary\", alpha = 0.3)\n",
    "\n",
    "    plt.scatter(x[:,0], x[:,1], s=5, c=y, cmap=cmap_py, edgecolor=\"k\", linewidths=0.2)\n",
    "    plt.xlim(-2.5,2.5)\n",
    "    plt.ylim(-1.6,2.5)\n",
    "    plt.title(\"KNN con K = \"+str(k))\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5696e062-0324-49bf-ac13-5d6f240d68e6",
   "metadata": {},
   "source": [
    "## 2. Fine Tuning en el algoritmo de KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e8dbc-bfbb-4a44-99c3-1bbf60e06557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Escogencia del hiperparámetro K\n",
    "vecinos = list(range(2, 100, 2))\n",
    "\n",
    "errores_insample = []\n",
    "errores_outsample = []\n",
    "for k in vecinos:\n",
    "    neigh = KNeighborsClassifier(n_neighbors = k)\n",
    "    neigh.fit(x_train, y_train)\n",
    "    y_hat_insample = neigh.predict(x_train)\n",
    "    y_hat_outsample = neigh.predict(x_test)\n",
    "\n",
    "    error_insample = (y_hat_insample != y_train).mean()\n",
    "    errores_insample.append(error_insample)\n",
    "    error_outsample = (y_hat_outsample != y_test).mean()\n",
    "    errores_outsample.append(error_outsample)\n",
    "\n",
    "resultados = pd.DataFrame({\"K\": vecinos, \"Error de entrenamiento\": errores_insample, \"Error de prueba\": errores_outsample})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd50c2-0d1f-43f9-943a-24343323d22e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 6), dpi = 100)\n",
    "sns.despine()\n",
    "\n",
    "sns.lineplot(data = resultados, x = \"K\", y = \"Error de entrenamiento\", ax = ax, color = \"darkblue\")\n",
    "sns.scatterplot(data = resultados, x = \"K\", y = \"Error de entrenamiento\", ax = ax, color = \"darkblue\")\n",
    "sns.lineplot(data = resultados, x = \"K\", y = \"Error de prueba\", ax = ax, color = \"orange\")\n",
    "sns.scatterplot(data = resultados, x = \"K\", y = \"Error de prueba\", ax = ax, color = \"orange\")\n",
    "ax.legend(handles = ax.lines, labels = [\"Entrenamiento\", \"Prueba\", \"Error irreducible\"])\n",
    "\n",
    "ax.set_xlabel(\"K Vecinos\")\n",
    "ax.set_ylabel(\"Error promedio\")\n",
    "ax.invert_xaxis()\n",
    "ax.yaxis.set_major_formatter(\"{x:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a860c-2d35-4253-839c-e9532716b32b",
   "metadata": {},
   "source": [
    "Del ejercicio anterior podríamos ver entonces que el número de vecinos óptimo es $K=20$, y que tendremos un error de predicción cercano al $6\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4df548-0224-4bef-a206-681a4f133208",
   "metadata": {},
   "source": [
    "### 3.SVM\n",
    "Veamos ahora la resolución al problema de clasificación cuando queremos implementar una SVM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef5adf-64b4-4994-a9a6-ad837945e34a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Recordemos la gráfica de las dos covariables\n",
    "plt.scatter(x[:,0],x[:,1],c=y)\n",
    "plt.xlabel(\"Edad\")\n",
    "plt.ylabel(\"Salario\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02999af0-4ee4-49c4-abf4-477751e274a7",
   "metadata": {},
   "source": [
    "Si intentamos hacer una SVM con kernel lineal habrán muchos clasificados de manera incorrecta...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b26b9-fad7-423a-944b-6e3458ef6a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model_svm = svm.SVC(kernel='linear', random_state=1,C=100)\n",
    "model_svm.fit(x,y)\n",
    "fig, ax = plt.subplots(figsize = (5, 5))\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(estimator = model_svm,  X = x, cmap = cmap_py,\n",
    "ax = ax, response_method = \"predict\", plot_method = \"contourf\",\n",
    "xlabel = \"Age\", ylabel = \"ExpectedSalary\", alpha = 0.3)\n",
    "\n",
    "plt.scatter(x[:,0], x[:,1], s=5, c=y, cmap=cmap_py, edgecolor=\"k\", linewidths=0.2)\n",
    "plt.xlim(-2.5,2.5)\n",
    "plt.ylim(-1.6,2.5)\n",
    "plt.title(\"SVM lineal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f576ca3-c375-472b-913e-8feabc5efa59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_svm.fit(x_train,y_train)\n",
    "y_pred_svm_naive=model_svm.predict(x_test)\n",
    "error=(y_pred_svm_naive!=y_test).mean()*100\n",
    "\n",
    "print(f\"Predijimos un {error:5.2f}% de datos en test incorrectamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c42ee-ef6b-4346-bb4a-20aaa0134235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Hagamos un SVM con kernel gaussiano\n",
    "model_svm={}\n",
    "gammas=[1,5,15]\n",
    "for gamma in gammas:\n",
    "    model_g = svm.SVC(kernel='rbf', random_state=1,gamma=gamma)\n",
    "    model_g.fit(x, y)\n",
    "    model_svm[\"svm_\" + str(gamma)] = model_g\n",
    "    print(model_svm)\n",
    "    fig, ax = plt.subplots(figsize = (5, 5))\n",
    "\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(estimator = model_svm[\"svm_\" + str(gamma)],  X = x, cmap = cmap_py,\n",
    "    ax = ax, response_method = \"predict\", plot_method = \"contourf\",\n",
    "    xlabel = \"Age\", ylabel = \"ExpectedSalary\", alpha = 0.3)\n",
    "\n",
    "    plt.scatter(x[:,0], x[:,1], s=5, c=y, cmap=cmap_py, edgecolor=\"k\", linewidths=0.2)\n",
    "    plt.xlim(-2.5,2.5)\n",
    "    plt.ylim(-1.6,2.5)\n",
    "    plt.title(\"SVM con kernel gaussiano y gamma \"+str(gamma))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab006212-903f-485a-a491-35ecef868ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Ejercicio- repita el proceso de construcción de la gráfica de escogencia del hiperparámetro para KNN, \n",
    "# fijando un SVM con kernel gaussiano y C=1. Qué valor de gamma minimiza el error en test? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f67b7-a3bb-4441-95ae-1e8a935e9cda",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Métricas de evaluación\n",
    "Veamos algunas métricas de evaluación de algoritmos y cómo hacer un _fine-tuning_ a los híper parámetros teniendo en cuenta cuáles son las métricas relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac28c9e-b0a4-4deb-8ed4-8372259852a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Un primer paso para identificar cuál métrica deberíamos usar, es ver el balanceo de las categorías en la muestra:\n",
    "datos['Purchased'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c212c-47d6-4c39-a243-d0c4584d1a0b",
   "metadata": {},
   "source": [
    "Está desbalanceado, pero no nos preocupamos inicialmente por esto. Es señal de alarma (por regla de pulgar) cuando hay una categoría con <10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28ea30-17b2-4ef6-921c-d230ece2401e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Recordemos el knn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "knn= KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "##Entrenamos nuestro modelo\n",
    "knn.fit(x_train,y_train)\n",
    "\n",
    "##Matriz de confusión\n",
    "y_pred=knn.predict(x_test)\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", square=True,\n",
    "            xticklabels=[\"Negative\", \"Positive\"],\n",
    "            yticklabels=[\"Negative\", \"Positive\"])\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30145067-c134-4e9d-a82e-e1acaca2bdf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Accuracy\n",
    "acc=metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"El accuracy score es \" + str(acc))\n",
    "\n",
    "##Precision\n",
    "pre=metrics.precision_score(y_test,y_pred)\n",
    "print(\"El precision score es \" + str(acc))\n",
    "\n",
    "##Recall\n",
    "rec=metrics.recall_score(y_test,y_pred)\n",
    "print(\"El precision score es \" + str(rec))\n",
    "\n",
    "##f1-score\n",
    "f1=metrics.f1_score(y_test,y_pred)\n",
    "print(\"El F1 score es \" + str(f1))\n",
    "\n",
    "##f_0.5 score\n",
    "fhalf=metrics.fbeta_score(y_test,y_pred,beta=0.5)\n",
    "print(\"El F_0.5 score es \" + str(fhalf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbb2d7-e789-4129-b37d-d9e374569db1",
   "metadata": {},
   "source": [
    "## Fine tuning con KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577ca70-3250-43e4-b522-4c36ef58e386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Hagamos un hiper-parameter tuning con knn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "knn_model = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 60, 2))\n",
    "}\n",
    "##Buscamos en grilla\n",
    "grid_search_knn = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "##Estamos haciendo cross-validación, sólamente hay que hacer un fit.\n",
    "grid_search_knn.fit(x, y)\n",
    "\n",
    "best_params_knn = grid_search_knn.best_params_\n",
    "best_score_knn = grid_search_knn.best_score_\n",
    "\n",
    "print(\"El mejor valor de k es\", best_params_knn)\n",
    "print(\"El mejor valor del accuracy: {:.2f}\".format(best_score_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac84e9-7576-4a23-a397-f66e500c5c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Habrá overfitting?\n",
    "knn_prueba= KNeighborsClassifier(n_neighbors=11)\n",
    "##Entrenamos nuestro modelo\n",
    "knn_prueba.fit(x_train,y_train)\n",
    "\n",
    "y_pred=knn_prueba.predict(x_test)\n",
    "y_pred_train=knn_prueba.predict(x_train) ##hacemos el predict en train set\n",
    "\n",
    "acc_test=metrics.accuracy_score(y_test,y_pred)\n",
    "acc_train=metrics.accuracy_score(y_train,y_pred_train)\n",
    "\n",
    "print(\"Accuracy en test: {:.2f}\".format(acc_test) )\n",
    "print(\"Accuracy ent train: {:.2f}\".format(acc_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716386b3-c615-49ea-a367-976c3e955d39",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fine tuning con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a03bd-fe37-4049-b36b-cc67aefdbc30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "svm_model = svm.SVC()\n",
    "param_grid_svm = {\n",
    "    'C': np.logspace(-3, 2, 10),\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma':  np.logspace(-3, 2, 10)\n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=svm_model, param_distributions=param_grid_svm, n_iter=45, cv=5, scoring='accuracy', random_state=42, verbose=1)\n",
    "\n",
    "random_search.fit(x, y)\n",
    "\n",
    "best_params_svm = random_search.best_params_\n",
    "best_score_svm = random_search.best_score_\n",
    "\n",
    "print(\"La mejor combinación de parámetros es\", best_params_svm)\n",
    "print(\"El mejor valor del accuracy: {:.2f}\".format(best_score_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdedc49-8d99-4e93-8f00-fccd2c2d3c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Ejercicio -> evalúe si hay overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b6ee1-169b-4a98-9f65-23eda40ec0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e08429",
   "metadata": {},
   "source": [
    "# Tareas - Ejercicios en clase "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4a6b0-4c3f-4e7b-b3b1-f4bff36a7761",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Utilizando ahora la variable de género, ¿Hay algún cambio en los resultados de la hiperparametrización de los modelos? Evalúe para KNN si es mejor añadir esta variable o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b4432-33eb-400e-b454-6e0ae862d528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c1e355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de74600f",
   "metadata": {},
   "source": [
    "### 2. Una más grande: Utilice los datos provenientes de scikit-learn para predecir la existencia de cáncer.  Utilice los modelos de KNN y SVM para predecir correctamente tumores malignos. Revise que sus algoritmos tuneados no tengan \"over-fitting\". Juegue con las covariables que van a ser relevantes en su modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd425d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# Crear un DataFrame con los datos\n",
    "df = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "\n",
    "# Añadir la columna target (objetivo)\n",
    "df['target'] = breast_cancer.target\n",
    "\n",
    "# Ver las primeras filas del DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Ver información básica del DataFrame\n",
    "print(\"\\nInformación del DataFrame:\")\n",
    "print(df.info())\n",
    "\n",
    "# Ver estadísticas descriptivas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Ver la distribución de clases\n",
    "print(\"\\nDistribución de clases (0: maligno, 1: benigno):\")\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37c55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1adc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
